# Interview Backend - Implementation Guide

> **Note:** This document provides implementation details and usage instructions. For the original assignment requirements, see [sre/README.md](sre/README.md).

## üìÅ Repository Structure

```
interview/
‚îú‚îÄ‚îÄ backend/                    # Spring Boot application
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile              # Multi-stage Docker build
‚îÇ   ‚îú‚îÄ‚îÄ entrypoint.sh           # Container entrypoint with JVM tuning
‚îÇ   ‚îú‚îÄ‚îÄ .dockerignore           # Docker build exclusions
‚îÇ   ‚îú‚îÄ‚îÄ pom.xml                 # Maven dependencies
‚îÇ   ‚îî‚îÄ‚îÄ src/                    # Application source code
‚îú‚îÄ‚îÄ sre/
‚îÇ   ‚îî‚îÄ‚îÄ helm/                   # Production-ready Helm chart
‚îÇ       ‚îú‚îÄ‚îÄ Chart.yaml          # Chart metadata
‚îÇ       ‚îú‚îÄ‚îÄ values-prod.yaml    # Production values
‚îÇ       ‚îî‚îÄ‚îÄ templates/
‚îÇ           ‚îú‚îÄ‚îÄ deployment.yaml
‚îÇ           ‚îú‚îÄ‚îÄ service.yaml
‚îÇ           ‚îú‚îÄ‚îÄ serviceaccount.yaml
‚îÇ           ‚îú‚îÄ‚îÄ ingress.yaml              # Dual ALB (public/private)
‚îÇ           ‚îú‚îÄ‚îÄ hpa.yaml                  # Horizontal Pod Autoscaler
‚îÇ           ‚îú‚îÄ‚îÄ pdb.yaml                  # Pod Disruption Budget
‚îÇ           ‚îú‚îÄ‚îÄ configmap.yaml            # Optional JVM config
‚îÇ           ‚îú‚îÄ‚îÄ servicemonitor.yaml       # Prometheus metrics
‚îÇ           ‚îú‚îÄ‚îÄ instrumentation.yaml      # OpenTelemetry auto-instrumentation
‚îÇ           ‚îú‚îÄ‚îÄ probes.yaml               # Blackbox Exporter SLA monitoring
‚îÇ           ‚îú‚îÄ‚îÄ iam.yaml                  # AWS IRSA (IAM Roles for Service Accounts)
‚îÇ           ‚îú‚îÄ‚îÄ secret-provider.yaml      # AWS Secrets Manager CSI driver
‚îÇ           ‚îú‚îÄ‚îÄ networkpolicy.yaml        # Network security policies
‚îÇ           ‚îî‚îÄ‚îÄ _helpers.tpl              # Reusable Helm templates
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ backend-cicd.yml    # CI/CD pipeline
‚îú‚îÄ‚îÄ Makefile                    # Development and testing commands
‚îú‚îÄ‚îÄ README.md                   # Original assignment
‚îî‚îÄ‚îÄ INTERVIEW.md                # This file
```

## üìã Prerequisites

### Infrastructure Prerequisites (I Already Deployed)

For this implementation, I'm using my existing personal sandbox AWS production environment with the following infrastructure already in place:

#### Infrastructure Layout

The following infrastructure is deployed via Terraform/Terragrunt and managed in a separate repository(not in PR):

```
terraform-infrastructure/
‚îú‚îÄ‚îÄ prod/
‚îÇ   ‚îî‚îÄ‚îÄ us-east-2/                    # Primary production region
‚îÇ       ‚îú‚îÄ‚îÄ aws-vpc/                  # Multi-AZ VPC with public/private subnets
‚îÇ       ‚îú‚îÄ‚îÄ aws-route53/              # Split-view dns public/private hosted zones
‚îÇ       ‚îú‚îÄ‚îÄ aws-acm/                  # TLS certificates
‚îÇ       ‚îú‚îÄ‚îÄ aws-ecr/                  # Container registry
‚îÇ       ‚îú‚îÄ‚îÄ aws-iam/                  # IAM roles and policies
‚îÇ       ‚îú‚îÄ‚îÄ aws-tf-state/             # Remote state with S3 + state locking
‚îÇ       ‚îú‚îÄ‚îÄ argocd/                   # ArgoCD ApplicationSets
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ developers.yaml       # ‚Üê Interview app ApplicationSet
‚îÇ       ‚îú‚îÄ‚îÄ github/                   # GitHub repo management, secrets, OIDC provider etc
‚îÇ       ‚îú‚îÄ‚îÄ openvpn/                  # VPN access server to access private resources
‚îÇ       ‚îî‚îÄ‚îÄ prod-eks/                 # EKS cluster with add-ons
‚îÇ           ‚îú‚îÄ‚îÄ Cluster (v1.33)
‚îÇ           ‚îú‚îÄ‚îÄ Node Groups (managed)
‚îÇ           ‚îú‚îÄ‚îÄ ArgoCD               # GitOps controller
‚îÇ           ‚îú‚îÄ‚îÄ AWS Load Balancer Controller
‚îÇ           ‚îú‚îÄ‚îÄ External DNS
‚îÇ           ‚îú‚îÄ‚îÄ Cert Manager
‚îÇ           ‚îú‚îÄ‚îÄ Stakater Reloader 
‚îÇ           ‚îú‚îÄ‚îÄ ACK IAM Controller
‚îÇ           ‚îú‚îÄ‚îÄ Cluster Autoscaler
‚îÇ           ‚îú‚îÄ‚îÄ Karpenter
‚îÇ           ‚îî‚îÄ‚îÄ Observability Stack:
‚îÇ               ‚îú‚îÄ‚îÄ Prometheus (kube-prometheus-stack)
‚îÇ               ‚îú‚îÄ‚îÄ Grafana
‚îÇ               ‚îú‚îÄ‚îÄ Loki             # Logs
‚îÇ               ‚îú‚îÄ‚îÄ Tempo            # Traces
‚îÇ               ‚îú‚îÄ‚îÄ Mimir            # Metrics
‚îÇ               ‚îú‚îÄ‚îÄ OpenTelemetry Collector
‚îÇ               ‚îú‚îÄ‚îÄ OpenTelemetry Operator
‚îÇ               ‚îî‚îÄ‚îÄ Blackbox Exporter
‚îî‚îÄ‚îÄ terraform-modules/                # Reusable Terraform modules
    ‚îú‚îÄ‚îÄ aws-vpc/
    ‚îú‚îÄ‚îÄ aws-eks/
    ‚îú‚îÄ‚îÄ aws-ecr/
    ‚îú‚îÄ‚îÄ aws-iam/
    ‚îú‚îÄ‚îÄ aws-acm/
    ‚îî‚îÄ‚îÄ ... (10+ modules)
```

> **Note:** The infrastructure setup (VPC, EKS, observability stack) is managed via Terraform in a separate 'terraform-infrastructure' repository with 10+ reusable modules in another separate 'terraform-modules' repo. This is not included in this PR to keep it focused on **application deployment** only as per take-home requirements. Happy to share though (^_^)

## üèóÔ∏è Architecture Overview

![GitOps CI/CD Architecture](sre/interview.jpg)

### Deployment Flow

1. **Developer** pushes code to GitHub
2. **GitHub Actions** (CI Server):
   - Builds Maven package
   - Creates Docker image
   - Pushes to Amazon ECR
   - Updates image tag in GitOps repo
   - PR is created pending prod approval
3. **ArgoCD** watches GitOps repo for changes
4. **ArgoCD** syncs manifests to EKS cluster
5. **Kubernetes** deploys new pods with updated image
6. **Application** reports health status back to ArgoCD

---

## üöÄ Quick Start

### Deploying to Your Existing Infrastructure

If you have an existing AWS EKS environment with the prerequisites listed above, deployment is straightforward:

1. **Update Helm Values** (`sre/helm/values-prod.yaml`):
   ```yaml
   aws:
     accountId: "YOUR_AWS_ACCOUNT_ID"
     region: "YOUR_AWS_REGION"
     eksName: "YOUR_EKS_CLUSTER_NAME"
     albCertificateArn: "YOUR_ACM_CERT_ARN"
     oidcProvider: "YOUR_OIDC_PROVIDER"
   
   image:
     repository: "YOUR_ECR_REPO"
     tag: "latest"
   ```

2. **Push to GitHub** - CI/CD pipeline automatically:
   - Builds Docker image
   - Pushes to your ECR
   - Updates GitOps repo with new image tag

3. **ArgoCD Syncs** - Automatically deploys to EKS

That's it! The application is now running with full observability.

---

### Local Development Prerequisites
- Docker
- Helm 3.x
- kubectl (configured with EKS cluster access)
- Make (optional, but recommended)

### Using the Makefile for local testing

The Makefile is located in the `sre/` directory for since this is a mono-repo with multiple projects.

```bash
# Navigate to sre directory
cd sre

# Show all available commands
make help

# Quick development workflow
make docker-build         # Build Docker image
make docker-run           # Start container
make docker-test          # Test /api/welcome endpoint
make docker-logs          # View logs
make docker-stop          # Stop container

# Validation workflows
make helm-lint            # Lint Helm chart
make helm-template        # Render Helm templates
make helm-dry-run         # Test Helm deployment (requires kubectl context)
make helm-validate        # Full Helm validation

# Combined workflows
make build-and-test       # Build, run, test, cleanup
make local-deploy         # Build + Helm dry-run
```
---

